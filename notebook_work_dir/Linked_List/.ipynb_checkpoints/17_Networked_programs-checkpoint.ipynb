{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. HyperText Transport Protocol - HTTP\n",
    "\n",
    "<pre>\n",
    "Сетевой протокол, управляющий веб, на самом деле довольно простой \n",
    "и Python имеет встроенную поддержку протокола, называемую sockets,\n",
    "которая дает возможность легко создавать сетевые подключения \n",
    "и получения данных из созданных сокетов в программе на Python.\n",
    "\n",
    "socket похож на файл, за исключением того, что \n",
    "один socket обеспечивает двустороннее соединение между двумя программами. \n",
    "\n",
    "Вы можете как читать так и писать в один и тот же сокет.\n",
    "\n",
    "Если вы что-то пишете в socket, данные отправляется в приложение на другом конце сокета.\n",
    "\n",
    "Если вы читаете из socket, вы получаете данные, которые другое приложения отправило.\n",
    "\n",
    "Если попытаться прочитать socket, когда программа на другом конце socket не послала никаких данных,\n",
    "то программа будет просто сидеть и ждать.\n",
    "\n",
    "Если программы на обоих концах socket ожидают получение данных, не посылая ничего,\n",
    "они будут ждать в течение очень долгого времени.\n",
    "\n",
    "Поэтому важной частью программ, которые общаются через Интернет яаляется необходимость иметь какой-то протокол.\n",
    "\n",
    "Протокол представляет собой набор четких правил, определяющих, кому идти в первую очередь,\n",
    "что необходимо делать в этот момент, какой должен быть ответ на данное сообщение, кто отправляет сообщение следующим, и так далее. \n",
    "\n",
    "В некотором смысле эти два приложения в обоих концах socket совершают танец и следят за тем,\n",
    "чтобы не наступать на ноги друг другу.\n",
    "\n",
    "Есть много документов, которые описывают эти сетевые протоколы.\n",
    "HyperText Transport Protocol описан в следующем документе:\n",
    "\n",
    "    http://www.w3.org/Protocols/rfc2616/rfc2616.txt\n",
    "\n",
    "Это большой и сложный 176-страничный документ с большим количеством деталей.\n",
    "На странице 36 RFC2616 вы найдете синтаксис запроса GET.\n",
    "\n",
    "Чтобы получить документ от веб-сервера, необходимо сделать подключение к серверу\n",
    "    \n",
    "      www.py4inf.com  \n",
    "      \n",
    "на порт \n",
    "\n",
    "    80\n",
    "    \n",
    "а затем отправить строку вида\n",
    "\n",
    "    GET http://www.py4inf.com/code/romeo.txt HTTP / 1.0\n",
    "\n",
    "где вторым параметром является веб-страница, которую мы затребовали, \n",
    "а затем отправить пустую строку.\n",
    "Веб-сервер ответит на запрос ответом, содержащим заголовок документа, пустой строкой, затем по содержанием документа.\n",
    "</pre>\n",
    "\n",
    "# 2. The World’s Simplest Web Browser\n",
    "\n",
    "<pre>\n",
    "Самый простой способ показать, как работает протокол HTTP - написать очень простую программу на языке Python,\n",
    "которая делает подключение к веб-серверу, следуя правилам протокола HTTP для запроса документа \n",
    "и отображает то, что сервер отправляет обратно.\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((\"www.py4inf.com\", 80))\n",
    "mysock.send(\"GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\\n\\n\")\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512) \n",
    "    if(len(data)<1):\n",
    "        break\n",
    "    print data\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Сначала программа делает подключение к порту 80 на сервере www.py4inf.com.\n",
    "Так как данная программа играет роль \"веб-браузера\",\n",
    "протокол HTTP говорит, что в таком случае необходимо отправить команду GET в последующей пустой строкой.\n",
    "</pre>\n",
    "\n",
    "<img src=\"network_first.png\"/>\n",
    "\n",
    "<pre>\n",
    "После того, как пустая строка отправлена, \n",
    "в теле цикла принимаются данные в виде 512-символьных блоков из socket и выводит данные на печать до тех пор,\n",
    "пока не будет больше данных для чтения\n",
    "(то есть RECV() вернет пустую строку).\n",
    "\n",
    "Содержимое ответа от веб-сервера начинается с заголовка, который веб-сервер посылает для описания документа.\n",
    "Например, заголовок Content-Type указывает, что документ это обычный текстовый документ (текст / обычный).\n",
    "После заголовка, добавляется пустая строка, чтобы указать конец заголовков, \n",
    "а затем отправляются фактические данные - файло romeo.txt.\n",
    "\n",
    "Этот пример показывает, как создать сетевое подключение на низком уровне, используя sockets.\n",
    "\n",
    "Sockets могут быть использованы для взаимодействия с веб-сервером или с почтовым сервером или с многими другими видами серверов.\n",
    "Все, что требуется, это найти документ, который описывает протокол взаимодействия с сервером и написать код для отправки и получения данных в соответствии с протоколом.\n",
    "\n",
    "Однако, поскольку протокол, который мы используем чаще всего является HTTP Web протоколом,\n",
    "Python имеет специальную библиотеку, специально разработанную для поддержки HTTP протокола для получения документов и данных по сети.\n",
    "</pre>\n",
    "\n",
    "# 3. Retrieving an image over HTTP\n",
    "\n",
    "<pre>\n",
    "В приведенном выше примере, мы получили обычный текстовый файл, который имеет новые строки в файле, \n",
    "и отобразили данные на экране.\n",
    "\n",
    "Можно использовать аналогичную программу для получения изображения  через HTTP.\n",
    "Вместо того чтобы отображать данные на экране,\n",
    "мы накапливаем данные в виде строки, обрезаем заголовки, \n",
    "а затем сохраняем данное изображение в файле следующим образом:\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socket \n",
    "import time\n",
    "\n",
    "# Create socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "# Open socket\n",
    "mysock.connect((\"www.py4inf.com\", 80))\n",
    "\n",
    "# Send data to the socket\n",
    "mysock.send(\"GET http://www.py4inf.com/cover.jpg HTTP/1.0\\n\\n\")\n",
    "\n",
    "count = 0 \n",
    "picture = \"\"\n",
    "\n",
    "# Retrieve the data from the socket\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if(len(data)<1): break \n",
    "    #time.sleep(0.25)\n",
    "    count += len(data) \n",
    "    print len(data), count \n",
    "    picture += data\n",
    "\n",
    "# Close socket\n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header (2 CRLF) \n",
    "pos = picture.find(\"\\r\\n\\r\\n\");\n",
    "print 'Header length',pos\n",
    "print picture[:pos]\n",
    "\n",
    "# Skip past the header and save the picture data \n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\",\"wb\")\n",
    "fhand.write(picture);\n",
    "fhand.close()\n",
    "\n",
    "# Show image\n",
    "# matplot\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "img=mpimg.imread('stuff.jpg')\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Вы можете видеть, для этого URL, заголовок Content-Type указывает на то,\n",
    "что тело документа представляет собой изображение (image/jpeg).\n",
    "После завершения программы можно просмотреть изображение, открыв файл stuff.jpg.\n",
    "\n",
    "Во время работы программы можно видеть,\n",
    "что мы не получаем 5120 символов каждый раз когда делается вызовметод recv(). \n",
    "Мы получаем столько символов, сколько было передано по сети к нам от веб-сервера в момент вызова recv().\n",
    "В данном примере, мы получаем 1460 или 2920 символов каждый раз,\n",
    "когда запрашивается до 5120 символов данных.\n",
    "\n",
    "Результаты могут отличаться в зависимости от скорости сети.\n",
    "Также обратите внимание, что последний вызов recv() мы получаем 1681 байт, \n",
    "это означает конец потока, а в следующем вызове recv() мы получаем строку нулевой длины,\n",
    "что говорит нам о том, что сервер вызвал close() на своей стороне для socket,\n",
    "и больше данных не предвидится.\n",
    "\n",
    "Мы можем замедлить последовательные вызовы recv()\n",
    "раскомментировав вызов time.sleep(). \n",
    "Таким образом, мы ждем четверть секунды после каждого вызова,\n",
    "так что сервер может \"опередить\" нас и отправить больше данных, прежде чем мы называем recv() еще раз.\n",
    "С задержкой вывод программы будет другим.\n",
    "\n",
    "Теперь, кроме первого и последнего вызова recv(), мы получаем 5120 символов каждый раз при запросе новых данных.\n",
    "Существует буфер между отправкой данных сервером send()\n",
    "и приемкой данных клиентом recv().\n",
    "Когда мы ставим задержки между чтениями из буфера, тогда сервер имеет возможность записать больше данных в буфер socket.\n",
    "Такой способ управления в приложении называется \"управление потоком\" (flow control).\n",
    "</pre>\n",
    "\n",
    "# 4. Retrieving web pages with urllib\n",
    "\n",
    "<pre>\n",
    "В то время как мы можем вручную отправлять и получать данные через HTTP с использованием библиотеки sockets,\n",
    "есть гораздо более простой способ выполнить эту общую задачу в Python с помощью библиотеки urllib.\n",
    "\n",
    "Используя urllib, вы можете рассматривать веб-страницы так же, как файл.\n",
    "Вы просто указываете, какие веб-страницы вы хотели бы получить \n",
    "и urllib обрабатывает протокол HTTP, заголовки и информацию.\n",
    "\n",
    "Аналогичный код для чтения файла romeo.txt из Интернета с помощью urllib выглядит следующим образом:\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "fhand = urllib.urlopen('http://www.py4inf.com/code/romeo.txt')\n",
    "for line in fhand:\n",
    "    print line.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "После того, как веб-страница была открыта с помощью urllib.urlopen,\n",
    "мы можем рассматривать ее как файл и прочитать его, используя цикл.\n",
    "\n",
    "При запуске программы, мы видим только вывод содержимого файла.\n",
    "Заголовки также присутствуют, но код urllib исключает заголовки и возвращает только данные.\n",
    "\n",
    "В качестве упражнения напишите программу, которая получает файл romeo.txt и вычисляет частоту каждого слова в файле.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your implementation here\n",
    "import urllib\n",
    "fhand = urllib.urlopen('http://www.py4inf.com/code/romeo.txt') \n",
    "for line in fhand:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Parsing HTML and scraping the web\n",
    "\n",
    "<pre>\n",
    "Одной из возможностей urllib в Python является возможность скрапить (scrape) Интернет.\n",
    "\n",
    "Под веб скрапингом подразумевается программа, которая имитирует поведение веб-браузера для извлечения страниц \n",
    "с последующим анализом данных на этих страницах.\n",
    "\n",
    "Например, поисковая система Google анализирует содержимое одной веб-страницы,\n",
    "извлекает из нее ссылки на другие страницы, запрашивает эти страницы, извлекает из них ссылки, и так далее.\n",
    "\n",
    "Используя эту технику, пауки (spiders) Google обходят почти все страницы в Интернете.\n",
    "\n",
    "Google также использует частоту ссылок на конкретную страницу с других страниц в качестве одной из метрик, \n",
    "насколько \"важна\" страница, и как высоко страница должна появиться в результатах поиска.\n",
    "</pre>\n",
    "\n",
    "# 6. Parsing HTML using regular expressions\n",
    "\n",
    "<pre>\n",
    "Одним из простых способов разбора HTML является использование регулярных выражений для поиска и извлечения подстроки, которые соответствуют определенному шаблону.\n",
    "\n",
    "Ниже представлен пример простой веб-страницы:\n",
    "</pre>\n",
    "\n",
    "```\n",
    "    <h1>The First Page</h1>\n",
    "    <p>\n",
    "    If you like, you can switch to the\n",
    "    <a href=\"http://www.dr-chuck.com/page2.htm\"> Second Page</a>.\n",
    "    </p>\n",
    "\n",
    "```\n",
    "\n",
    "<pre>\n",
    "Мы можем построить регулярное выражение для поиска и извлечения значения ссылку из текста выше следующим образом:\n",
    "\n",
    "    href=\"http://.+?\"\n",
    "\n",
    "Наша регулярное выражение ищет строки, которые начинаются с \"href=\"http://\"\n",
    "а затем один или более символов (\"+.?\"), затем еще одни двойные кавычки.\n",
    "Знак вопроса, добавленный к \"+.?\" указывает на то, что поиск совпадений будет сделан в режиме \"не жадный\".\n",
    "\n",
    "Мы добавим скобки в наше регулярное выражение, чтобы указать, какую часть нашей совпавшей строки мы хотели бы извлечь.\n",
    "Метод  регулярного выражения findall даст нам список всех строк, которые соответствуют нашему регулярному выражению, возвращая только текст ссылки между двойными кавычками.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "\n",
    "url = raw_input('Enter a url: ')\n",
    "html = urllib.urlopen(url).read()\n",
    "links = re.findall('href=\"(http://.*?)\"', html)\n",
    "for link in links:\n",
    "    print link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Регулярные выражения работают хорошо, когда HTML правильно сформирован.\n",
    "Но так как судествует много \"битых\" HTML-страниц,\n",
    "решение с использоваинем регулярных выражений может либо пропустить некоторые действительные ссылки или в конечном итоге вернуть плохие данные.\n",
    "\n",
    "Это может быть решено с помощью  библиотеки HTML парсера.\n",
    "</pre>\n",
    "\n",
    "# 7. Parsing HTML using scrapy \n",
    "\n",
    "<pre>\n",
    "Существует ряд библиотек Python, которые помогают обрабатывать HTML и извлекать данные из страниц.\n",
    "Каждая из библиотек имеет свои сильные и слабые стороны, и выбор делается в зависимости от потребностей.\n",
    "В качестве примера расмотрим простой парсер HTML и извлечение ссылок, используя библиотеку scrapy.\n",
    "Вы можете скачать и установить библиотеку scrapy:\n",
    "\n",
    "    http://scrapy.org\n",
    "    \n",
    "Scrapy позволяет легко извлекать необходимые данные из html и xml документов.\n",
    "Мы будем использовать urllib для получения страницы,\n",
    "а затем использовать scrapy для извлечения href атрибутов из тега (a).\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "import urllib\n",
    "\n",
    "url = raw_input('Enter a url: ')\n",
    "html = urllib.urlopen(url).read()\n",
    "\n",
    "# Retrieve all of the anchor tags \n",
    "tags = Selector(text=html).xpath('//a/@href').extract()\n",
    "for tag in tags:\n",
    "    print tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pre>\n",
    "Можно использовать scrapy для извлечения разных атрибутов тега.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "import urllib\n",
    "\n",
    "urls = [\"http://ubotstudio.com/\",\n",
    "       \"http://www.80legs.com/\",\n",
    "       \"http://docs.seleniumhq.org/\",\n",
    "       \"http://www.scrapy.org\",\n",
    "       \"http://casperjs.org/\",\n",
    "       \"http://nutch.apache.org/\",\n",
    "       \"http://nokogiri.org/\"]\n",
    "\n",
    "for url in urls:\n",
    "    html = urllib.urlopen(url).read()\n",
    "\n",
    "    # Retrieve all of the anchor tags \n",
    "    tags = Selector(text=html).xpath('//title/text()').extract()\n",
    "    for tag in tags:\n",
    "        print tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Reading binary files using urllib\n",
    "\n",
    "<pre>\n",
    "Иногда необходимо получить не текст а двоичный файл, \n",
    "например, файл в виде изображения или видео.\n",
    "\n",
    "Данные в этих файлах, как правило, не предназначены для печати, но можно легко скопировать url в локальный файл на жестком диске с помощью urllib.\n",
    "\n",
    "Схема выглядит следующим образом: открыть url, загрузить все содержимое документа в строковую переменную и записать эту информацию в локальный файл.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = urllib.urlopen('http://www.py4inf.com/cover.jpg').read()\n",
    "with open('cover.jpg', 'w') as f:\n",
    "    f.write(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Эта программа читает все данные сразу и сохраняет его в переменной img в основной памяти компьютера, \n",
    "а затем открывает файл cover.jpg и записывает данные на диск.\n",
    "Данный подход будет работать, если размер файла меньше, чем размер памяти вашего компьютера.\n",
    "\n",
    "Однако, если это большой аудио или видео файл, эта программа может зависнуть \n",
    "или по крайней мере работать крайне медленно, так как размер оперативной памяти компьютера будет исчерпан.\n",
    "Для того, чтобы избежать нехватки памяти, мы принимаем данные блоками,\n",
    "а затем записываем каждый блок на диск перед извлечением следующего блока.\n",
    "Таким образом, программа может прочитать любой размер файла, не используя всю память компьютера.\n",
    "\n",
    "В этом примере, мы читаем только 100000 символов за раз,\n",
    "а затем записываем полученные данные в файл cover.jpg перед извлечением следующего блока данных в 100000 символов из Интернета.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "img = urllib.urlopen('http://www.py4inf.com/cover.jpg') \n",
    "fhand = open('cover.jpg', 'w')\n",
    "size=0\n",
    "while True:\n",
    "    info = img.read(100000) \n",
    "    if len(info)<1 : break \n",
    "    size += len(info)\n",
    "    fhand.write(info)\n",
    "print size,'characters copied.' \n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## 1.\n",
    "<pre>\n",
    "В качестве упражнения модифицируйте предыдущую программу таким образом, чтобы:\n",
    "\n",
    "    - url задавался пользователем (raw_input)\n",
    "    - имя файла на диске совпадало с именем файла, полученным из интернет, то есть, для url http://www.w3.org/Protocols/rfc2616/rfc2616.txt соответсвовало имя файла rfc2616.txt. Подсказка: используйте метод split() для разделения строки url на отдельные слова\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your implementation\n",
    "import urllib\n",
    "img = urllib.urlopen('http://www.py4inf.com/cover.jpg') \n",
    "fhand = open('cover.jpg', 'w')\n",
    "size=0\n",
    "while True:\n",
    "    info = img.read(100000) \n",
    "    if len(info)<1 : break \n",
    "    size += len(info)\n",
    "    fhand.write(info)\n",
    "print size,'characters copied.' \n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "<pre>\n",
    "В качестве упражнения модифицируйте следующую программу таким образом, чтобы:\n",
    "\n",
    "    - url задавался пользователем (raw_input)\n",
    "    - используя метод split(\"/\") разделите url на составляющие для извлечения и передачи имени хоста методу connect()\n",
    "    - добавьте обработку исключений try / except для случаев некорректного ввода пользователем адреса. Подсказка: используйте тип исключения socket.error\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your implementation\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('www.py4inf.com', 80))\n",
    "mysock.send('GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\\n\\n')\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(100)\n",
    "    if (len(data)<1):break\n",
    "    print data\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "<pre>\n",
    "Измените программу socket таким образом, чтобы она подсчитывала количество символов, \n",
    "которые она получила, и перестала отображать текст после того, как было выведено на экран 3000 символов.\n",
    "Программа должна извлечь весь документ и подсчитать общее число символов и отобразить общее количество полученных символов в конце документа.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your implementation\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('www.py4inf.com', 80))\n",
    "mysock.send('GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\\n\\n')\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(100)\n",
    "    if (len(data)<1): break\n",
    "    print data\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "<pre>\n",
    "Перепишите предыдущую программу, используя urllib вместо socket.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your implementation\n",
    "import urllib\n",
    "\n",
    "fhand = urllib.urlopen('http://www.py4inf.com/code/romeo.txt')\n",
    "for line in fhand:\n",
    "    print line.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "<pre>\n",
    "Измените следующую программу таким образом, чтобы:\n",
    "\n",
    "    - извлечь и подсчитать количество тегов (р) из извлеченного HTML документа и отобразить подсчитанное число параграфов в качестве выхода программы.\n",
    "    \n",
    "Проверьте вашу программу на нескольких веб-страницах.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "import urllib\n",
    "\n",
    "url = raw_input('Enter a url: ')\n",
    "html = urllib.urlopen(url).read()\n",
    "\n",
    "# Retrieve all of the anchor tags \n",
    "tags = Selector(text=html).xpath('//a/@href').extract()\n",
    "for tag in tags:\n",
    "    print tag\n",
    "    \n",
    "# test \n",
    "html = \"\"\"<h1>The First Page</h1>\n",
    "    <p>\n",
    "    If you like, you can switch to the\n",
    "    <a href=\"http://www.dr-chuck.com/page2.htm\"> Second Page</a>.\n",
    "    </p><p>p</p>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "<pre>\n",
    "Измените программу socket таким образом, чтобы она показывала только данные без заголовка.\n",
    "Помните, что recv() получает символы, не сроки.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your implementation\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('www.py4inf.com', 80))\n",
    "mysock.send('GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\\n\\n')\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(100)\n",
    "    if (len(data)<1): break\n",
    "    print data\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
